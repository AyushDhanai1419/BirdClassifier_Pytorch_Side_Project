{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Notebook_BirdClassifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushDhanai1419/BirdClassifier_Pytorch_Side_Project/blob/master/Train_Notebook_BirdClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PQC0ki5iz0R8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Developing an AI application\n",
        "\n",
        "## Bird Classifier 200 different species\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "77DpikmnbyyZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing Pytorch"
      ]
    },
    {
      "metadata": {
        "id": "3yIxr5zwlNgd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "  \n",
        "# Installed pillow\n",
        "!pip install Pillow==4.0.0\n",
        "\n",
        "# Installed gdown\n",
        "!pip install gdown==3.6.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dm4wfNlgdv9W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing modules"
      ]
    },
    {
      "metadata": {
        "id": "GFczFIhQz0SN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.optim import lr_scheduler\n",
        "import seaborn as sns\n",
        "\n",
        "# imported PIl.image\n",
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pMJGQeYNbrSO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading Birds Dataset"
      ]
    },
    {
      "metadata": {
        "id": "-RjZwjI3lyuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Downloadin dataset\n",
        "my_file_id = \"1qaLPSrqFqylRVoh4KrEKs9wpXv7L6sAS\"\n",
        "!gdown https://drive.google.com/uc?id={my_file_id}\n",
        "!unzip BirdsImages.zip\n",
        "\n",
        "# Downloading Actual labels\n",
        "my_file_id = \"1v_Vex6cGhrsMF3FAe4WdnhD3iiNxWdJ5\"\n",
        "!gdown https://drive.google.com/uc?id={my_file_id}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-T9gM3ISz0S6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the data\n"
      ]
    },
    {
      "metadata": {
        "id": "4zeCv2OTz0TD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "\n",
        "data_dir = 'images'\n",
        "\n",
        "\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir, transform=train_transforms)\n",
        "\n",
        "\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 90\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.3\n",
        "again_split = 0.5\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "\n",
        "num_train = len(valid_idx)\n",
        "indicess = list(range(num_train))\n",
        "split = int(np.floor(again_split * len(valid_idx)))\n",
        "valid_idx, test_idx = indicess[split:], indicess[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=test_sampler, num_workers=num_workers)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AE6ovY-WiWHm",
        "colab_type": "code",
        "outputId": "8810a649-2b0e-4796-873d-336f1005547f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Displaying Total Images\n",
        "\n",
        "print('Total images : ',len(train_data))\n",
        "print('Total train images : ',len(train_idx))\n",
        "print('Total valid images : ',len(valid_idx))\n",
        "print('Total test images : ',len(test_idx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images :  6033\n",
            "Total train images :  4224\n",
            "Total valid images :  905\n",
            "Total test images :  904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wMAL7zvz0Tk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Label mapping\n",
        "\n",
        "You'll also need to load in a mapping from category label to category name. You can find this in the file `classes.txt`. "
      ]
    },
    {
      "metadata": {
        "id": "dPZ4QWc1z0Tv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bird_to_name = {}\n",
        "with open(\"/content/classes.txt\") as f:\n",
        "    for line in f:\n",
        "      key, val = line.rstrip(\"\\n\").split('.')\n",
        "      bird_to_name[int(key)] = val     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MzE76Gqm9h_A",
        "colab_type": "code",
        "outputId": "2172c8f5-a01f-41bd-8eff-ddb9251ef37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(bird_to_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'Black_footed_Albatross', 2: 'Laysan_Albatross', 3: 'Sooty_Albatross', 4: 'Groove_billed_Ani', 5: 'Crested_Auklet', 6: 'Least_Auklet', 7: 'Parakeet_Auklet', 8: 'Rhinoceros_Auklet', 9: 'Brewer_Blackbird', 10: 'Red_winged_Blackbird', 11: 'Rusty_Blackbird', 12: 'Yellow_headed_Blackbird', 13: 'Bobolink', 14: 'Indigo_Bunting', 15: 'Lazuli_Bunting', 16: 'Painted_Bunting', 17: 'Cardinal', 18: 'Spotted_Catbird', 19: 'Gray_Catbird', 20: 'Yellow_breasted_Chat', 21: 'Eastern_Towhee', 22: 'Chuck_will_Widow', 23: 'Brandt_Cormorant', 24: 'Red_faced_Cormorant', 25: 'Pelagic_Cormorant', 26: 'Bronzed_Cowbird', 27: 'Shiny_Cowbird', 28: 'Brown_Creeper', 29: 'American_Crow', 30: 'Fish_Crow', 31: 'Black_billed_Cuckoo', 32: 'Mangrove_Cuckoo', 33: 'Yellow_billed_Cuckoo', 34: 'Gray_crowned_Rosy_Finch', 35: 'Purple_Finch', 36: 'Northern_Flicker', 37: 'Acadian_Flycatcher', 38: 'Great_Crested_Flycatcher', 39: 'Least_Flycatcher', 40: 'Olive_sided_Flycatcher', 41: 'Scissor_tailed_Flycatcher', 42: 'Vermilion_Flycatcher', 43: 'Yellow_bellied_Flycatcher', 44: 'Frigatebird', 45: 'Northern_Fulmar', 46: 'Gadwall', 47: 'American_Goldfinch', 48: 'European_Goldfinch', 49: 'Boat_tailed_Grackle', 50: 'Eared_Grebe', 51: 'Horned_Grebe', 52: 'Pied_billed_Grebe', 53: 'Western_Grebe', 54: 'Blue_Grosbeak', 55: 'Evening_Grosbeak', 56: 'Pine_Grosbeak', 57: 'Rose_breasted_Grosbeak', 58: 'Pigeon_Guillemot', 59: 'California_Gull', 60: 'Glaucous_winged_Gull', 61: 'Heermann_Gull', 62: 'Herring_Gull', 63: 'Ivory_Gull', 64: 'Ring_billed_Gull', 65: 'Slaty_backed_Gull', 66: 'Western_Gull', 67: 'Anna_Hummingbird', 68: 'Ruby_throated_Hummingbird', 69: 'Rufous_Hummingbird', 70: 'Green_Violetear', 71: 'Long_tailed_Jaeger', 72: 'Pomarine_Jaeger', 73: 'Blue_Jay', 74: 'Florida_Jay', 75: 'Green_Jay', 76: 'Dark_eyed_Junco', 77: 'Tropical_Kingbird', 78: 'Gray_Kingbird', 79: 'Belted_Kingfisher', 80: 'Green_Kingfisher', 81: 'Pied_Kingfisher', 82: 'Ringed_Kingfisher', 83: 'White_breasted_Kingfisher', 84: 'Red_legged_Kittiwake', 85: 'Horned_Lark', 86: 'Pacific_Loon', 87: 'Mallard', 88: 'Western_Meadowlark', 89: 'Hooded_Merganser', 90: 'Red_breasted_Merganser', 91: 'Mockingbird', 92: 'Nighthawk', 93: 'Clark_Nutcracker', 94: 'White_breasted_Nuthatch', 95: 'Baltimore_Oriole', 96: 'Hooded_Oriole', 97: 'Orchard_Oriole', 98: 'Scott_Oriole', 99: 'Ovenbird', 100: 'Brown_Pelican', 101: 'White_Pelican', 102: 'Western_Wood_Pewee', 103: 'Sayornis', 104: 'American_Pipit', 105: 'Whip_poor_Will', 106: 'Horned_Puffin', 107: 'Common_Raven', 108: 'White_necked_Raven', 109: 'American_Redstart', 110: 'Geococcyx', 111: 'Loggerhead_Shrike', 112: 'Great_Grey_Shrike', 113: 'Baird_Sparrow', 114: 'Black_throated_Sparrow', 115: 'Brewer_Sparrow', 116: 'Chipping_Sparrow', 117: 'Clay_colored_Sparrow', 118: 'House_Sparrow', 119: 'Field_Sparrow', 120: 'Fox_Sparrow', 121: 'Grasshopper_Sparrow', 122: 'Harris_Sparrow', 123: 'Henslow_Sparrow', 124: 'Le_Conte_Sparrow', 125: 'Lincoln_Sparrow', 126: 'Nelson_Sharp_tailed_Sparrow', 127: 'Savannah_Sparrow', 128: 'Seaside_Sparrow', 129: 'Song_Sparrow', 130: 'Tree_Sparrow', 131: 'Vesper_Sparrow', 132: 'White_crowned_Sparrow', 133: 'White_throated_Sparrow', 134: 'Cape_Glossy_Starling', 135: 'Bank_Swallow', 136: 'Barn_Swallow', 137: 'Cliff_Swallow', 138: 'Tree_Swallow', 139: 'Scarlet_Tanager', 140: 'Summer_Tanager', 141: 'Artic_Tern', 142: 'Black_Tern', 143: 'Caspian_Tern', 144: 'Common_Tern', 145: 'Elegant_Tern', 146: 'Forsters_Tern', 147: 'Least_Tern', 148: 'Green_tailed_Towhee', 149: 'Brown_Thrasher', 150: 'Sage_Thrasher', 151: 'Black_capped_Vireo', 152: 'Blue_headed_Vireo', 153: 'Philadelphia_Vireo', 154: 'Red_eyed_Vireo', 155: 'Warbling_Vireo', 156: 'White_eyed_Vireo', 157: 'Yellow_throated_Vireo', 158: 'Bay_breasted_Warbler', 159: 'Black_and_white_Warbler', 160: 'Black_throated_Blue_Warbler', 161: 'Blue_winged_Warbler', 162: 'Canada_Warbler', 163: 'Cape_May_Warbler', 164: 'Cerulean_Warbler', 165: 'Chestnut_sided_Warbler', 166: 'Golden_winged_Warbler', 167: 'Hooded_Warbler', 168: 'Kentucky_Warbler', 169: 'Magnolia_Warbler', 170: 'Mourning_Warbler', 171: 'Myrtle_Warbler', 172: 'Nashville_Warbler', 173: 'Orange_crowned_Warbler', 174: 'Palm_Warbler', 175: 'Pine_Warbler', 176: 'Prairie_Warbler', 177: 'Prothonotary_Warbler', 178: 'Swainson_Warbler', 179: 'Tennessee_Warbler', 180: 'Wilson_Warbler', 181: 'Worm_eating_Warbler', 182: 'Yellow_Warbler', 183: 'Northern_Waterthrush', 184: 'Louisiana_Waterthrush', 185: 'Bohemian_Waxwing', 186: 'Cedar_Waxwing', 187: 'American_Three_toed_Woodpecker', 188: 'Pileated_Woodpecker', 189: 'Red_bellied_Woodpecker', 190: 'Red_cockaded_Woodpecker', 191: 'Red_headed_Woodpecker', 192: 'Downy_Woodpecker', 193: 'Bewick_Wren', 194: 'Cactus_Wren', 195: 'Carolina_Wren', 196: 'House_Wren', 197: 'Marsh_Wren', 198: 'Rock_Wren', 199: 'Winter_Wren', 200: 'Common_Yellowthroat'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KiaFD9v3z0UB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building and training the classifier\n"
      ]
    },
    {
      "metadata": {
        "id": "VYYDoW1rVPf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2a_gKfF2C5LG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I270PMkRz0UH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Build and train your network\n",
        "\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.classifier = nn.Sequential(nn.Linear(1024, 512),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(512, 200),\n",
        "                                 nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Only train the classifier parameters, feature parameters are frozen\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 8 epochs\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "\n",
        "model.class_to_idx = train_data.class_to_idx\n",
        "model.to('cuda');\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btCVsl_lk2b5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If Unfreezed Required\n",
        "\n",
        "for i , param in enumerate(model.parameters()):    #468 parameters\n",
        "    if(i>300):\n",
        "      param.requires_grad=True\n",
        "      \n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCwO544ZRQOA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_pV-HPjEUma",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training Model"
      ]
    },
    {
      "metadata": {
        "id": "pQyw3cZuSNwr",
        "colab_type": "code",
        "outputId": "09973c76-caef-48e8-9806-a9cb970b2442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 60\n",
        "\n",
        "# initialize tracker for minimum validation loss\n",
        "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    scheduler.step()\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train() # prep model for training\n",
        "    for data, target in train_loader:\n",
        "        \n",
        "        # Move input and label tensors to the default device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model.forward(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval() # prep model for evaluation\n",
        "    for data, target in valid_loader:\n",
        "        # Move input and label tensors to the default device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model.forward(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update running validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 3.438211 \tValidation Loss: 0.575735\n",
            "Validation loss decreased (inf --> 0.575735).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 2.427846 \tValidation Loss: 0.392271\n",
            "Validation loss decreased (0.575735 --> 0.392271).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 1.793059 \tValidation Loss: 0.290282\n",
            "Validation loss decreased (0.392271 --> 0.290282).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 1.465282 \tValidation Loss: 0.254644\n",
            "Validation loss decreased (0.290282 --> 0.254644).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 1.271637 \tValidation Loss: 0.213947\n",
            "Validation loss decreased (0.254644 --> 0.213947).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 1.107793 \tValidation Loss: 0.213665\n",
            "Validation loss decreased (0.213947 --> 0.213665).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.990791 \tValidation Loss: 0.197315\n",
            "Validation loss decreased (0.213665 --> 0.197315).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.933778 \tValidation Loss: 0.207192\n",
            "Epoch: 9 \tTraining Loss: 0.854429 \tValidation Loss: 0.164623\n",
            "Validation loss decreased (0.197315 --> 0.164623).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.824059 \tValidation Loss: 0.177182\n",
            "Epoch: 11 \tTraining Loss: 0.737702 \tValidation Loss: 0.151177\n",
            "Validation loss decreased (0.164623 --> 0.151177).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.741602 \tValidation Loss: 0.161961\n",
            "Epoch: 13 \tTraining Loss: 0.657953 \tValidation Loss: 0.165295\n",
            "Epoch: 14 \tTraining Loss: 0.671166 \tValidation Loss: 0.153916\n",
            "Epoch: 15 \tTraining Loss: 0.624528 \tValidation Loss: 0.148698\n",
            "Validation loss decreased (0.151177 --> 0.148698).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 0.586116 \tValidation Loss: 0.163459\n",
            "Epoch: 17 \tTraining Loss: 0.586217 \tValidation Loss: 0.149502\n",
            "Epoch: 18 \tTraining Loss: 0.577662 \tValidation Loss: 0.130556\n",
            "Validation loss decreased (0.148698 --> 0.130556).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 0.514325 \tValidation Loss: 0.137793\n",
            "Epoch: 20 \tTraining Loss: 0.536891 \tValidation Loss: 0.142049\n",
            "Epoch: 21 \tTraining Loss: 0.509632 \tValidation Loss: 0.157973\n",
            "Epoch: 22 \tTraining Loss: 0.524547 \tValidation Loss: 0.143425\n",
            "Epoch: 23 \tTraining Loss: 0.484424 \tValidation Loss: 0.137603\n",
            "Epoch: 24 \tTraining Loss: 0.469313 \tValidation Loss: 0.133793\n",
            "Epoch: 25 \tTraining Loss: 0.465599 \tValidation Loss: 0.148191\n",
            "Epoch: 26 \tTraining Loss: 0.443660 \tValidation Loss: 0.138663\n",
            "Epoch: 27 \tTraining Loss: 0.451930 \tValidation Loss: 0.131472\n",
            "Epoch: 28 \tTraining Loss: 0.431950 \tValidation Loss: 0.125086\n",
            "Validation loss decreased (0.130556 --> 0.125086).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 0.419588 \tValidation Loss: 0.135592\n",
            "Epoch: 30 \tTraining Loss: 0.432438 \tValidation Loss: 0.129703\n",
            "Epoch: 31 \tTraining Loss: 0.427416 \tValidation Loss: 0.121697\n",
            "Validation loss decreased (0.125086 --> 0.121697).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 0.395083 \tValidation Loss: 0.143944\n",
            "Epoch: 33 \tTraining Loss: 0.438435 \tValidation Loss: 0.119674\n",
            "Validation loss decreased (0.121697 --> 0.119674).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 0.416007 \tValidation Loss: 0.134573\n",
            "Epoch: 35 \tTraining Loss: 0.386236 \tValidation Loss: 0.124023\n",
            "Epoch: 36 \tTraining Loss: 0.433353 \tValidation Loss: 0.133262\n",
            "Epoch: 37 \tTraining Loss: 0.389560 \tValidation Loss: 0.158237\n",
            "Epoch: 38 \tTraining Loss: 0.392185 \tValidation Loss: 0.124454\n",
            "Epoch: 39 \tTraining Loss: 0.365439 \tValidation Loss: 0.132624\n",
            "Epoch: 40 \tTraining Loss: 0.391058 \tValidation Loss: 0.129287\n",
            "Epoch: 41 \tTraining Loss: 0.374820 \tValidation Loss: 0.126312\n",
            "Epoch: 42 \tTraining Loss: 0.381124 \tValidation Loss: 0.120952\n",
            "Epoch: 43 \tTraining Loss: 0.325383 \tValidation Loss: 0.127541\n",
            "Epoch: 44 \tTraining Loss: 0.349101 \tValidation Loss: 0.139735\n",
            "Epoch: 45 \tTraining Loss: 0.382783 \tValidation Loss: 0.129371\n",
            "Epoch: 46 \tTraining Loss: 0.344192 \tValidation Loss: 0.131917\n",
            "Epoch: 47 \tTraining Loss: 0.336593 \tValidation Loss: 0.117887\n",
            "Validation loss decreased (0.119674 --> 0.117887).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 0.360913 \tValidation Loss: 0.130835\n",
            "Epoch: 49 \tTraining Loss: 0.341782 \tValidation Loss: 0.132087\n",
            "Epoch: 50 \tTraining Loss: 0.328072 \tValidation Loss: 0.121881\n",
            "Epoch: 51 \tTraining Loss: 0.343812 \tValidation Loss: 0.126914\n",
            "Epoch: 52 \tTraining Loss: 0.345957 \tValidation Loss: 0.132892\n",
            "Epoch: 53 \tTraining Loss: 0.342881 \tValidation Loss: 0.121097\n",
            "Epoch: 54 \tTraining Loss: 0.326786 \tValidation Loss: 0.125834\n",
            "Epoch: 55 \tTraining Loss: 0.331962 \tValidation Loss: 0.132090\n",
            "Epoch: 56 \tTraining Loss: 0.340660 \tValidation Loss: 0.105369\n",
            "Validation loss decreased (0.117887 --> 0.105369).  Saving model ...\n",
            "Epoch: 57 \tTraining Loss: 0.331649 \tValidation Loss: 0.136283\n",
            "Epoch: 58 \tTraining Loss: 0.342202 \tValidation Loss: 0.118929\n",
            "Epoch: 59 \tTraining Loss: 0.313398 \tValidation Loss: 0.120658\n",
            "Epoch: 60 \tTraining Loss: 0.299635 \tValidation Loss: 0.141452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tLxyrxMdfJOD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading model.pt \n",
        "\n",
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TlhpHLAXz0UZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the checkpoint\n",
        "\n",
        "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
        "\n",
        "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
        "\n",
        "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
      ]
    },
    {
      "metadata": {
        "id": "itW093C4QgBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a2OvU3Riplnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_save_name = 'UnFreezedModel_densenet121_2L_60epochs_batch90.pt'\n",
        "path = F\"/content/gdrive/My Drive/Colab Notebooks/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}